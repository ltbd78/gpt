{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b21d2fa-a70a-46c7-8fec-762e613994e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from attention import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765dff59-cc66-4e21-9da8-e3f0e3e6c932",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365138cf-5cda-4ed0-ba00-3add5f15fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b20d69-a1c1-4e06-bf04-1f93ae091476",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_dim = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f470c1a4-9404-4821-90aa-1d0cdd17898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_i = {c:i for i, c in enumerate(chars)}\n",
    "i_c = {i:c for i, c in enumerate(chars)}\n",
    "encode = lambda s: [c_i[c] for c in s]\n",
    "decode = lambda l: ''.join([i_c[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49afe273-9dc6-4b13-8e6e-bb4e8ecfa846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.int64)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7069bbb2-a37e-4cda-8daa-560c85413398",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(.9*len(data))\n",
    "data_train = data[:n]\n",
    "data_val = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d569f291-59dc-432a-8afd-2c8e1bb54bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003854"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37762abb-7b6c-4b36-b4e1-f4d64bdc73eb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "002df69c-a553-460b-a2e5-4a657d4229dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # N\n",
    "sequence_dim = 100 # L, S\n",
    "embed_dim = 78 # E\n",
    "num_heads = 13 # H\n",
    "assert embed_dim % num_heads == 0\n",
    "train_steps = 5000\n",
    "lr = 1e-3 # learning rate\n",
    "torch.manual_seed(78)\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feef2df7-f1d6-4466-be9d-eb680a7e96ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, N, L):\n",
    "    idx = torch.randint(len(data) - L, (N,))\n",
    "    x = torch.stack([data[i:i+L] for i in idx])\n",
    "    y = torch.stack([data[i+1:i+L+1] for i in idx])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7c6c23-f653-4546-8174-3ede608aed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_batch(data_train, batch_size, sequence_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71bf040d-8c32-49b5-ae4d-cce70f0fef5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 100]), torch.Size([64, 100]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c83a1895-b760-4b9c-b441-ed693ed14832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.9706,  1.8401,  0.7425,  1.7492],\n",
       "           [-0.4090, -0.7430,  1.5891, -0.6899],\n",
       "           [-1.9549, -1.1546, -2.9000, -1.6289]],\n",
       " \n",
       "          [[ 0.4538,  0.8432, -0.4011, -0.3256],\n",
       "           [-2.4454,  0.1959,  0.3256,  0.2596],\n",
       "           [-1.1855, -1.0788,  0.5622, -0.4791]]]]),)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1, 2, 3, 4).split(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c77cc01-9835-456e-8aa2-4167373da7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',\\nAnd spurn upon thee, beggar, for thy boldness.\\n\\nLADY ANNE:\\nWhat, do you tremble? are you all afrai', ' for,\\nif thou beest capable of things serious, thou must\\nknow the king is full of grief.\\n\\nShepard:\\nS', ' and twenty nose-gays for\\nthe shearers, three-man-song-men all, and very good\\nones; but they are mos', ' a trueborn Englishman.\\n\\nKING RICHARD II:\\nWe did observe. Cousin Aumerle,\\nHow far brought you high H', \"been gadding?\\n\\nJULIET:\\nWhere I have learn'd me to repent the sin\\nOf disobedient opposition\\nTo you an\", \":\\nHe makes a July's day short as December,\\nAnd with his varying childness cures in me\\nThoughts that \", 'uld break a thousand oaths to reign one year.\\n\\nRICHARD:\\nNo; God forbid your grace should be forsworn', 'hy with some little train, my Lord of Buckingham?\\n\\nBUCKINGHAM:\\nMarry, my lord, lest, by a multitude,', 'on,\\nAnd then be gone and trouble you no more.\\nShall I obtain it?\\n\\nHENRY BOLINGBROKE:\\nName it, fair c', \"leather bottle.\\nHis wonted sleep under a fresh tree's shade,\\nAll which secure and sweetly he enjoys,\", 'companion by the hand,\\nWho hath a story ready for your ear.\\nI shall attend your leisure: but make ha', \"such unity in the proofs. The mantle\\nof Queen Hermione's, her jewel about the neck of it,\\nthe letter\", 'n for that, my dear?\\nThe pale moon shines by night:\\nAnd when I wander here and there,\\nI then do most', ' dim his glory and to stain the track\\nOf his bright passage to the occident.\\n\\nDUKE OF YORK:\\nYet look', 'd to take my leave of you.\\nHow now, my as fair as noble ladies,--and the moon,\\nwere she earthly, no ', 'fices,\\nSo rarely kind, are as interpreters\\nOf my behind-hand slackness. Welcome hither,\\nAs is the sp', \"ected; stopp'd your ears against\\nThe general suit of Rome; never admitted\\nA private whisper, no, not\", ' gall;\\nAnd do him right that, answering one foul wrong,\\nLives not to act another. Be satisfied;\\nYour', 'ew men rightly temper with the stars:\\nYet in this one thing let me blame your grace,\\nFor choosing me', 'at Time himself doth say\\nHe wishes earnestly you never may.\\n\\nPOLIXENES:\\nI pray thee, good Camillo, b', 'ink and paper ready?\\n\\nRATCLIFF:\\nIt is, my lord.\\n\\nKING RICHARD III:\\nBid my guard watch; leave me.\\nRat', 'ession;\\nNot hold thee of our blood, no, not our kin,\\nFar than Deucalion off: mark thou my words:\\nFol', 'Should pass this way as you did: O, the Fates!\\nHow would he look, to see his work so noble\\nVilely bo', 'you, Signior Gremio.\\n\\nGREMIO:\\nAnd you are well met, Signior Hortensio.\\nTrow you whither I am going? ', 'ifteen years! by my fay, a goodly nap.\\nBut did I never speak of all that time?\\n\\nFirst Servant:\\nO, ye', \"Gracious my lord,\\nYou know your father's temper: at this time\\nHe will allow no speech, which I do gu\", 'hould have leave to go away betimes,\\nLest in our need he might infect another\\nAnd make him of like s', 'll experience grows. But in a few,\\nSignior Hortensio, thus it stands with me:\\nAntonio, my father, is', \"fence:\\nUnsheathe your sword, good father; cry 'Saint George!'\\n\\nEDWARD:\\nNow, perjured Henry! wilt tho\", 'pass the abuse done to my niece?\\nDid I impale him with the regal crown?\\nDid I put Henry from his nat', \"sight as this?\\n\\nLADY CAPULET:\\nAccursed, unhappy, wretched, hateful day!\\nMost miserable hour that e'e\", 'to you; and with speed so pace\\nTo speak of Perdita, now grown in grace\\nEqual with wondering: what of', 'liction, to themselves are dead;\\nAnd liberty plucks justice by the nose;\\nThe baby beats the nurse, a', 'd not be a stander-by to hear\\nMy sovereign mistress clouded so, without\\nMy present vengeance taken: ', \"while; we'll hear a little more.\\n\\nKING HENRY VI:\\nMy queen and son are gone to France for aid;\\nAnd, a\", ':\\nCan Oxford, that did ever fence the right,\\nNow buckler falsehood with a pedigree?\\nFor shame! leave', \"ht\\nHave my old feet stumbled at graves! Who's there?\\n\\nBALTHASAR:\\nHere's one, a friend, and one that \", 'ly triumphs, mirthful comic shows,\\nSuch as befits the pleasure of the court?\\nSound drums and trumpet', \"t long I shall not stay\\nI shall return before your lordship thence.\\n\\nHASTINGS:\\n'Tis like enough, for\", \"d o'er divides him\\n'Twixt his unkindness and his kindness; the one\\nHe chides to hell and bids the ot\", \"the sword unsway'd?\\nIs the king dead? the empire unpossess'd?\\nWhat heir of York is there alive but w\", \"y ill\\n'Gainst us, our state, our subjects, or our land.\\n\\nHENRY BOLINGBROKE:\\nI swear.\\n\\nTHOMAS MOWBRAY\", 'el, from the world:\\nHis head is off and sent to Angelo.\\n\\nISABELLA:\\nNay, but it is not so.\\n\\nDUKE VINC', 'se and ply his book, welcome his friends,\\nVisit his countrymen and banquet them?\\n\\nLUCENTIO:\\nBasta; c', \"be so.\\n\\nCORIOLANUS:\\nYou common cry of curs! whose breath I hate\\nAs reek o' the rotten fens, whose lo\", ' four wanton springs\\nEnd in a word: such is the breath of kings.\\n\\nJOHN OF GAUNT:\\nI thank my liege, t', \" the queen:\\nIf she dares trust me with her little babe,\\nI'll show't the king and undertake to be\\nHer\", 'nail, finger:\\nAnd thou, good goddess Nature, which hast made it\\nSo like to him that got it, if thou ', \"s shall seem, as partly 'tis, their own,\\nWhich we have goaded onward.\\n\\nCORIOLANUS:\\nTullus Aufidius t\", 's? The matter? speak, I pray you.\\n\\nFirst Citizen:\\nOur business is not unknown to the senate; they ha', 'ands do;\\nThey pray, grant thou, lest faith turn to despair.\\n\\nJULIET:\\nSaints do not move, though gran', 'n,\\nShall cross the seas, and bid false Edward battle;\\nAnd, as occasion serves, this noble queen\\nAnd ', ' foretold that danger lurks within.\\n\\nKING EDWARD IV:\\nTush, man, abodements must not now affright us:', 'y:\\nRouse up thy youthful blood, be valiant and live.\\n\\nHENRY BOLINGBROKE:\\nMine innocency and Saint Ge', \"than question how 'tis born.\\nIf therefore you dare trust my honesty,\\nThat lies enclosed in this trun\", ' storm\\nThat mortal ears might hardly endure the din?\\n\\nLUCENTIO:\\nTranio, I saw her coral lips to move', \"im'd it nor deserved it;\\nAnd therefore, in mine opinion, cannot have it:\\nThen, taking him from thenc\", ' first gentleman-like\\ntears that ever we shed.\\n\\nShepherd:\\nWe may live, son, to shed many more.\\n\\nClow', \"rs mounted run their horse to death.\\n'Tis beauty that doth oft make women proud;\\nBut, God he knows, \", \"ll employ me in,\\nWere it to call King Edward's widow sister,\\nI will perform it to enfranchise you.\\nM\", 'to his human powers\\nAnd gave him graceful posture.\\n\\nSICINIUS:\\nOn the sudden,\\nI warrant him consul.\\n\\n', 'erhand corrupted foul injustice,\\nIf that your moody discontented souls\\nDo through the clouds behold ', 'ows bound with victorious wreaths;\\nOur bruised arms hung up for monuments;\\nOur stern alarums changed', ' poor fellow, sir.\\nI know ye well enough.\\n\\nCAMILLO:\\nNay, prithee, dispatch: the gentleman is half\\nfl']\n",
      "['\\nAnd spurn upon thee, beggar, for thy boldness.\\n\\nLADY ANNE:\\nWhat, do you tremble? are you all afraid', 'for,\\nif thou beest capable of things serious, thou must\\nknow the king is full of grief.\\n\\nShepard:\\nSo', 'and twenty nose-gays for\\nthe shearers, three-man-song-men all, and very good\\nones; but they are most', 'a trueborn Englishman.\\n\\nKING RICHARD II:\\nWe did observe. Cousin Aumerle,\\nHow far brought you high He', \"een gadding?\\n\\nJULIET:\\nWhere I have learn'd me to repent the sin\\nOf disobedient opposition\\nTo you and\", \"\\nHe makes a July's day short as December,\\nAnd with his varying childness cures in me\\nThoughts that w\", 'ld break a thousand oaths to reign one year.\\n\\nRICHARD:\\nNo; God forbid your grace should be forsworn.', 'y with some little train, my Lord of Buckingham?\\n\\nBUCKINGHAM:\\nMarry, my lord, lest, by a multitude,\\n', 'n,\\nAnd then be gone and trouble you no more.\\nShall I obtain it?\\n\\nHENRY BOLINGBROKE:\\nName it, fair co', \"eather bottle.\\nHis wonted sleep under a fresh tree's shade,\\nAll which secure and sweetly he enjoys,\\n\", 'ompanion by the hand,\\nWho hath a story ready for your ear.\\nI shall attend your leisure: but make has', \"uch unity in the proofs. The mantle\\nof Queen Hermione's, her jewel about the neck of it,\\nthe letters\", ' for that, my dear?\\nThe pale moon shines by night:\\nAnd when I wander here and there,\\nI then do most ', 'dim his glory and to stain the track\\nOf his bright passage to the occident.\\n\\nDUKE OF YORK:\\nYet looks', ' to take my leave of you.\\nHow now, my as fair as noble ladies,--and the moon,\\nwere she earthly, no n', 'ices,\\nSo rarely kind, are as interpreters\\nOf my behind-hand slackness. Welcome hither,\\nAs is the spr', \"cted; stopp'd your ears against\\nThe general suit of Rome; never admitted\\nA private whisper, no, not \", 'gall;\\nAnd do him right that, answering one foul wrong,\\nLives not to act another. Be satisfied;\\nYour ', 'w men rightly temper with the stars:\\nYet in this one thing let me blame your grace,\\nFor choosing me ', 't Time himself doth say\\nHe wishes earnestly you never may.\\n\\nPOLIXENES:\\nI pray thee, good Camillo, be', 'nk and paper ready?\\n\\nRATCLIFF:\\nIt is, my lord.\\n\\nKING RICHARD III:\\nBid my guard watch; leave me.\\nRatc', 'ssion;\\nNot hold thee of our blood, no, not our kin,\\nFar than Deucalion off: mark thou my words:\\nFoll', 'hould pass this way as you did: O, the Fates!\\nHow would he look, to see his work so noble\\nVilely bou', 'ou, Signior Gremio.\\n\\nGREMIO:\\nAnd you are well met, Signior Hortensio.\\nTrow you whither I am going? T', 'fteen years! by my fay, a goodly nap.\\nBut did I never speak of all that time?\\n\\nFirst Servant:\\nO, yes', \"racious my lord,\\nYou know your father's temper: at this time\\nHe will allow no speech, which I do gue\", 'ould have leave to go away betimes,\\nLest in our need he might infect another\\nAnd make him of like sp', 'l experience grows. But in a few,\\nSignior Hortensio, thus it stands with me:\\nAntonio, my father, is ', \"ence:\\nUnsheathe your sword, good father; cry 'Saint George!'\\n\\nEDWARD:\\nNow, perjured Henry! wilt thou\", 'ass the abuse done to my niece?\\nDid I impale him with the regal crown?\\nDid I put Henry from his nati', \"ight as this?\\n\\nLADY CAPULET:\\nAccursed, unhappy, wretched, hateful day!\\nMost miserable hour that e'er\", 'o you; and with speed so pace\\nTo speak of Perdita, now grown in grace\\nEqual with wondering: what of ', 'iction, to themselves are dead;\\nAnd liberty plucks justice by the nose;\\nThe baby beats the nurse, an', \" not be a stander-by to hear\\nMy sovereign mistress clouded so, without\\nMy present vengeance taken: '\", \"hile; we'll hear a little more.\\n\\nKING HENRY VI:\\nMy queen and son are gone to France for aid;\\nAnd, as\", '\\nCan Oxford, that did ever fence the right,\\nNow buckler falsehood with a pedigree?\\nFor shame! leave ', \"t\\nHave my old feet stumbled at graves! Who's there?\\n\\nBALTHASAR:\\nHere's one, a friend, and one that k\", 'y triumphs, mirthful comic shows,\\nSuch as befits the pleasure of the court?\\nSound drums and trumpets', \" long I shall not stay\\nI shall return before your lordship thence.\\n\\nHASTINGS:\\n'Tis like enough, for \", \" o'er divides him\\n'Twixt his unkindness and his kindness; the one\\nHe chides to hell and bids the oth\", \"he sword unsway'd?\\nIs the king dead? the empire unpossess'd?\\nWhat heir of York is there alive but we\", \" ill\\n'Gainst us, our state, our subjects, or our land.\\n\\nHENRY BOLINGBROKE:\\nI swear.\\n\\nTHOMAS MOWBRAY:\", 'l, from the world:\\nHis head is off and sent to Angelo.\\n\\nISABELLA:\\nNay, but it is not so.\\n\\nDUKE VINCE', 'e and ply his book, welcome his friends,\\nVisit his countrymen and banquet them?\\n\\nLUCENTIO:\\nBasta; co', \"e so.\\n\\nCORIOLANUS:\\nYou common cry of curs! whose breath I hate\\nAs reek o' the rotten fens, whose lov\", 'four wanton springs\\nEnd in a word: such is the breath of kings.\\n\\nJOHN OF GAUNT:\\nI thank my liege, th', \"the queen:\\nIf she dares trust me with her little babe,\\nI'll show't the king and undertake to be\\nHer \", 'ail, finger:\\nAnd thou, good goddess Nature, which hast made it\\nSo like to him that got it, if thou h', \" shall seem, as partly 'tis, their own,\\nWhich we have goaded onward.\\n\\nCORIOLANUS:\\nTullus Aufidius th\", '? The matter? speak, I pray you.\\n\\nFirst Citizen:\\nOur business is not unknown to the senate; they hav', 'nds do;\\nThey pray, grant thou, lest faith turn to despair.\\n\\nJULIET:\\nSaints do not move, though grant', ',\\nShall cross the seas, and bid false Edward battle;\\nAnd, as occasion serves, this noble queen\\nAnd p', 'foretold that danger lurks within.\\n\\nKING EDWARD IV:\\nTush, man, abodements must not now affright us:\\n', ':\\nRouse up thy youthful blood, be valiant and live.\\n\\nHENRY BOLINGBROKE:\\nMine innocency and Saint Geo', \"han question how 'tis born.\\nIf therefore you dare trust my honesty,\\nThat lies enclosed in this trunk\", 'storm\\nThat mortal ears might hardly endure the din?\\n\\nLUCENTIO:\\nTranio, I saw her coral lips to move\\n', \"m'd it nor deserved it;\\nAnd therefore, in mine opinion, cannot have it:\\nThen, taking him from thence\", 'first gentleman-like\\ntears that ever we shed.\\n\\nShepherd:\\nWe may live, son, to shed many more.\\n\\nClown', \"s mounted run their horse to death.\\n'Tis beauty that doth oft make women proud;\\nBut, God he knows, t\", \"l employ me in,\\nWere it to call King Edward's widow sister,\\nI will perform it to enfranchise you.\\nMe\", 'o his human powers\\nAnd gave him graceful posture.\\n\\nSICINIUS:\\nOn the sudden,\\nI warrant him consul.\\n\\nB', 'rhand corrupted foul injustice,\\nIf that your moody discontented souls\\nDo through the clouds behold t', 'ws bound with victorious wreaths;\\nOur bruised arms hung up for monuments;\\nOur stern alarums changed ', 'poor fellow, sir.\\nI know ye well enough.\\n\\nCAMILLO:\\nNay, prithee, dispatch: the gentleman is half\\nfla']\n"
     ]
    }
   ],
   "source": [
    "print([decode(l) for l in x.numpy()])\n",
    "print([decode(l) for l in y.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b6abfe2-2cf1-4de5-99b5-0a91d92d78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features, 4 * out_features), # TODO: 4x according to paper\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * in_features, out_features), # projection layer\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3f96167-a645-4536-98d7-9a9ab3213069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionBlock(nn.Module):\n",
    "    def __init__(self, sequence_dim, embed_dim, num_heads, dropout=0.2): # L, E, H\n",
    "        super().__init__()\n",
    "        # self.register_buffer(\"attn_mask\", torch.triu(torch.full((sequence_dim, sequence_dim), float('-inf')), diagonal=1)) # flavor 1 - pytorch\n",
    "        self.register_buffer(\"attn_mask\", torch.tril(torch.ones(sequence_dim, sequence_dim)) == 0) # flavor 2 - karpathy\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(embed_dim) # https://arxiv.org/pdf/2002.04745.pdf\n",
    "        self.mha = MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.ff = FeedForward(embed_dim, embed_dim, dropout=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ln1(x)\n",
    "        attn_output, attn_output_weights = self.mha(x, x, x, need_weights=True, attn_mask=self.attn_mask, is_causal=True) # self attend\n",
    "        x = x + attn_output\n",
    "        x = x + self.ff(self.ln2(x)) # think on data\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ff20584-e4e4-45aa-a0a0-9516a97abc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_dim, sequence_dim, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.sequence_dim = sequence_dim\n",
    "        \n",
    "        self.token_embedding = nn.Embedding(vocab_dim, embed_dim)\n",
    "        self.position_embedding = nn.Embedding(sequence_dim, embed_dim)\n",
    "        self.blocks = nn.Sequential(\n",
    "            SelfAttentionBlock(sequence_dim, embed_dim, num_heads),\n",
    "            SelfAttentionBlock(sequence_dim, embed_dim, num_heads),\n",
    "            SelfAttentionBlock(sequence_dim, embed_dim, num_heads),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "        )\n",
    "        self.linear = nn.Linear(embed_dim, vocab_dim)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        # N is batch, L is length of time series, E is embedding dim\n",
    "        N, L = x.shape\n",
    "        token_embeddings = self.token_embedding(x) # (N, L, E)\n",
    "        position_embeddings = self.position_embedding(torch.arange(L).to(device)) # (L, E) # T <= sequence_dim\n",
    "        x = token_embeddings + position_embeddings # (N, L, E) +  (-, L, E) -> (N, L, E)\n",
    "        x = self.blocks(x)\n",
    "        logits = self.linear(x) # pred\n",
    "        if y is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            N, L, E = logits.shape\n",
    "            logits = logits.view(N*L, E)\n",
    "            y = y.view(N*L)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, x, n_tokens):\n",
    "        for i in range(n_tokens):\n",
    "            x_cropped = x[:, -self.sequence_dim:] # crop s.t. it's <= sequence_dim\n",
    "            logits, _ = self(x_cropped) # (N, L, E)\n",
    "            logits = logits[:, -1, :] # (N, E)\n",
    "            probs = F.softmax(logits, dim=-1) # (N, E)\n",
    "            y_pred = torch.multinomial(probs, num_samples=1) # (N, 1)\n",
    "            x = torch.cat((x, y_pred), dim=1) # (N, L) + (N, 1) = (N, L + 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5b0e80f-829d-4cb3-b944-2860cb9a7a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(vocab_dim, sequence_dim, embed_dim, num_heads).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90e66b27-247d-4e36-ae45-c8b14fa71852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (token_embedding): Embedding(65, 78)\n",
       "  (position_embedding): Embedding(100, 78)\n",
       "  (blocks): Sequential(\n",
       "    (0): SelfAttentionBlock(\n",
       "      (ln1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiheadAttention(\n",
       "        (query): Linear(in_features=78, out_features=78, bias=False)\n",
       "        (key): Linear(in_features=78, out_features=78, bias=False)\n",
       "        (value): Linear(in_features=78, out_features=78, bias=False)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (projection): Linear(in_features=78, out_features=78, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=78, out_features=312, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=312, out_features=78, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionBlock(\n",
       "      (ln1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiheadAttention(\n",
       "        (query): Linear(in_features=78, out_features=78, bias=False)\n",
       "        (key): Linear(in_features=78, out_features=78, bias=False)\n",
       "        (value): Linear(in_features=78, out_features=78, bias=False)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (projection): Linear(in_features=78, out_features=78, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=78, out_features=312, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=312, out_features=78, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SelfAttentionBlock(\n",
       "      (ln1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiheadAttention(\n",
       "        (query): Linear(in_features=78, out_features=78, bias=False)\n",
       "        (key): Linear(in_features=78, out_features=78, bias=False)\n",
       "        (value): Linear(in_features=78, out_features=78, bias=False)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (projection): Linear(in_features=78, out_features=78, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=78, out_features=312, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=312, out_features=78, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=78, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27240457-ada0-4c64-a51d-bd83bd150886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xbc$nPcNyCfW.y\n",
      "o.z?,yLFzgsK'sD:3sY$bZdLeyLSpr3D-wvF,W.e.Pibgj.NDwFQBmY\n",
      "LMhGVIiir&x3cbv&s'oaSyiv.t3jR\n"
     ]
    }
   ],
   "source": [
    "# pre training\n",
    "print(decode(model.generate(torch.zeros((sequence_dim, sequence_dim), dtype=torch.int64).to(device), 100).cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "746ba3c0-3f54-42e4-90ca-4bd353b04013",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, iters, device):\n",
    "    out = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    losses = torch.zeros(iters)\n",
    "    for data in [data_train, data_val]:\n",
    "        for i in range(iters):\n",
    "            x, y = get_batch(data, batch_size, sequence_dim)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits, loss = model(x, y)\n",
    "            losses[i] = loss.item()\n",
    "        out.append(losses.mean())\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08852f4a-0be8-495e-a74c-295a5360888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0399) tensor(4.0498)\n",
      "tensor(2.1530) tensor(2.1911)\n",
      "tensor(1.8653) tensor(1.9626)\n",
      "tensor(1.7370) tensor(1.8729)\n",
      "tensor(1.6652) tensor(1.8210)\n",
      "tensor(1.6200) tensor(1.7882)\n",
      "tensor(1.5879) tensor(1.7570)\n",
      "tensor(1.5731) tensor(1.7515)\n",
      "tensor(1.5505) tensor(1.7238)\n",
      "tensor(1.5323) tensor(1.7157)\n",
      "CPU times: total: 17.5 s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tenth = train_steps//10\n",
    "for steps in range(train_steps):\n",
    "    x, y = get_batch(data_train, batch_size, sequence_dim)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    logits, loss = model(x, y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if steps % tenth == 0:\n",
    "        train_loss, val_loss = estimate_loss(model, 100, device)\n",
    "        print(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4874f602-4a11-4864-baed-aef55e0a66f0",
   "metadata": {},
   "source": [
    "batch_size = 78 # N\n",
    "sequence_dim = 78 # L, S\n",
    "embed_dim = 80 # E\n",
    "num_heads = 4 # H\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "---\n",
    "\n",
    "# gpt_slow\n",
    "tensor(4.0853) tensor(4.0914)\n",
    "tensor(2.2387) tensor(2.2676)\n",
    "tensor(1.9001) tensor(1.9818)\n",
    "tensor(1.7665) tensor(1.8968)\n",
    "tensor(1.6842) tensor(1.8525)\n",
    "tensor(1.6364) tensor(1.8077)\n",
    "tensor(1.6067) tensor(1.7912)\n",
    "tensor(1.5796) tensor(1.7645)\n",
    "tensor(1.5626) tensor(1.7489)\n",
    "tensor(1.5503) tensor(1.7344)\n",
    "CPU times: total: 17.7 s\n",
    "Wall time: 2min 18s\n",
    "\n",
    "--\n",
    "\n",
    "# gpt.py\n",
    "tensor(4.1103) tensor(4.1171)\n",
    "tensor(2.2146) tensor(2.2454)\n",
    "tensor(1.9044) tensor(1.9912)\n",
    "tensor(1.7589) tensor(1.8970)\n",
    "tensor(1.6818) tensor(1.8554)\n",
    "tensor(1.6294) tensor(1.8055)\n",
    "tensor(1.5991) tensor(1.7882)\n",
    "tensor(1.5724) tensor(1.7519)\n",
    "tensor(1.5554) tensor(1.7445)\n",
    "tensor(1.5431) tensor(1.7225)\n",
    "CPU times: total: 15.6 s\n",
    "Wall time: 1min 18s\n",
    "\n",
    "--\n",
    "\n",
    "# nn.MultiheadAttention need_weights=False\n",
    "tensor(4.0348) tensor(4.0430)\n",
    "tensor(2.0703) tensor(2.1172)\n",
    "tensor(1.8026) tensor(1.9151)\n",
    "tensor(1.6848) tensor(1.8374)\n",
    "tensor(1.6148) tensor(1.7976)\n",
    "tensor(1.5705) tensor(1.7458)\n",
    "tensor(1.5401) tensor(1.7284)\n",
    "tensor(1.5155) tensor(1.6991)\n",
    "tensor(1.4989) tensor(1.6899)\n",
    "tensor(1.4894) tensor(1.6676)\n",
    "CPU times: total: 9.72 s\n",
    "Wall time: 1min 10s\n",
    "\n",
    "--\n",
    "\n",
    "## nn.MultiheadAttention need_weights=True\n",
    "tensor(4.0349) tensor(4.0431)\n",
    "tensor(2.0726) tensor(2.1189)\n",
    "tensor(1.8041) tensor(1.9145)\n",
    "tensor(1.6837) tensor(1.8336)\n",
    "tensor(1.6111) tensor(1.7881)\n",
    "tensor(1.5713) tensor(1.7465)\n",
    "tensor(1.5369) tensor(1.7249)\n",
    "tensor(1.5130) tensor(1.6915)\n",
    "tensor(1.4976) tensor(1.6814)\n",
    "tensor(1.4849) tensor(1.6590)\n",
    "CPU times: total: 14.3 s\n",
    "Wall time: 1min 13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4ed5851-494a-479c-9d10-8d59ebdf2fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FIRTIUS:\n",
      "No, let him your agreed\n",
      "The hear come I dear; I tell 'tis full treak.\n",
      "\n",
      "ARCHOP,\n",
      "So were to the orsong, ever crison's your good tell do me.\n",
      "\n",
      "POLIXENES:\n",
      "That king of deed.\n",
      "To bood. What, and your jest discreed;\n",
      "Or know your gaents Richard many to enjet,\n",
      "That that, this chappet to steak pearle friends of thin\n",
      "along is receive us amer! rangely the l'd cheely\n",
      "youth peace. When brief, my fortune, for as so;\n",
      "Thou shumbled upon his una was womanish,\n",
      "Will to be yield. What you.\n",
      "\n",
      "JOHN OF GOFORK:\n",
      "Mord news, royal womd\n",
      "Those in haste the receeqe's in with \n",
      "PANLIA:\n",
      "I sto-content! which anothing the Romanation\n",
      "As mone and in the rupposed, or wish peptater:\n",
      "Here liecte ease thee tyranner:\n",
      "These but be to affidge unto her more,\n",
      "To father and fiar up of at justicion new!\n",
      "Where shall did a comfort to her?\n",
      "Montabst the arsabed, the det you earth; I keep,\n",
      "He we lopking: my pacity deserved\n",
      "Spishrot from. Sweet King Richard, he and my father?\n",
      "\n",
      "CLIFTER:\n",
      "I do not counselow.\n",
      "\n",
      "SICINIUS:\n",
      "Tell and and out\n"
     ]
    }
   ],
   "source": [
    "# post training\n",
    "model.eval()\n",
    "print(decode(model.generate(torch.zeros((sequence_dim, sequence_dim), dtype=torch.int64).to(device), 1000).cpu().numpy()[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
