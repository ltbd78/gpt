{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c68724-883e-4aaf-b7af-e9c55cde389a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb071fa-a81c-4182-aa71-2c253a4d7ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = <your-project-id>\n",
    "! gcloud config set project $PROJECT_ID\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = REPOSITORY_NAME = \"lh-sandbox\"\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI\n",
    "! gsutil ls -al $BUCKET_URI\n",
    "OUTPUT_IMAGE_URI = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY_NAME}/gpt_deployment:latest\"\n",
    "MODEL_DISPLAY_NAME = \"gpt\"\n",
    "DIR_SRC = \"src\"\n",
    "DIR_MODEL_ARTIFACTS = \"model_artifacts\" # required files genereated in gpt.ipynb: tiktoken_config.pkl, model_config.pkl, gpt.pth\n",
    "!gsutil cp {DIR_MODEL_ARTIFACTS}/* {BUCKET_URI}/{DIR_MODEL_ARTIFACTS}/\n",
    "!gsutil ls {BUCKET_URI}/{DIR_MODEL_ARTIFACTS}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc55484-73c7-4455-9905-13403746b2cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "from src.gcp_predictor import GPTPredictor  # Update this path as the variable $DIR_SRC to import the custom predictor.\n",
    "\n",
    "# https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.prediction.LocalModel\n",
    "local_model = LocalModel.build_cpr_model(\n",
    "    DIR_SRC, # everything here is copied to image\n",
    "    OUTPUT_IMAGE_URI, # final output image\n",
    "    predictor=GPTPredictor,\n",
    "    # handler=, # use default\n",
    "    requirements_path=os.path.join(DIR_SRC, \"deploy_requirements.txt\"),\n",
    "    # no_cache=True, # to rebuild everything\n",
    "    # base_image=, # base_image ENTRYPOINT/CMD will be overriden\n",
    ")\n",
    "# to debug: docker run -it --entrypoint /bin/bash <image>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cdf94f-a63f-4af3-81ae-51c1d897f256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df0d153-2594-4640-bd1f-5e9eccd744b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write a JSON prediciton request\n",
    "# if timeout error, reduce the size of instances array\n",
    "!echo '{\"instances\": [\"linsu\", \"han\"]}' > instances.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2facaa32-24ed-4702-ba34-2858aec4d25e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# local deployment, local storage\n",
    "with local_model.deploy_to_local_endpoint(artifact_uri=f\"{DIR_MODEL_ARTIFACTS}\") as local_endpoint:\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file=\"instances.json\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "    health_check_response = local_endpoint.run_health_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1cb6ff-0036-4682-849d-dc800a2a46c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_response, predict_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fad5cf-5b01-4ec1-a87c-84911057aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_check_response, health_check_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d636666-d255-44f8-a516-c4913c73e195",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# local deployment, gcp storage\n",
    "with local_model.deploy_to_local_endpoint(artifact_uri=f\"{BUCKET_URI}/{DIR_MODEL_ARTIFACTS}\") as local_endpoint: #, credential_path=CREDENTIALS_FILE\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file=\"instances.json\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "    health_check_response = local_endpoint.run_health_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a3fe8-bb80-4778-848a-c6577cf145a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_response, predict_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3986e-fffe-4a4e-aad9-e1485f0bbfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "health_check_response, health_check_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ed94e-a90a-4d80-9458-b4aa67e4dfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_model.push_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f64a4d-ad0b-434c-9edd-bdd787beefe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from google.cloud import aiplatform\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "model = aiplatform.Model.upload(\n",
    "    local_model=local_model,\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=f\"{BUCKET_URI}/{DIR_MODEL_ARTIFACTS}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a72fd6-b0fc-445a-a45e-53ee755b91bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49284d-6c36-4813-b54c-1f3f2a5895f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# prediction using python\n",
    "endpoint.predict(instances=[\"test\", \"hi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd7196-1a7d-46a1-a374-64e9cb31f5a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENDPOINT_ID = endpoint.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7227a-619d-4da3-93b1-9b60f18525e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# prediction using cli\n",
    "!gcloud ai endpoints predict $ENDPOINT_ID --region $REGION --json-request instances.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f6bab-5410-486a-bc75-2f6346e4a582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# using REST\n",
    "!curl -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" -d @instances.json https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}:pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a76ca4-b1fc-4c1c-bdfe-ffe4f12ec80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cleanup\n",
    "\n",
    "# # Undeploy model and delete endpoint\n",
    "# endpoint.delete(force=True)\n",
    "\n",
    "# # Delete the model resource\n",
    "# model.delete()\n",
    "\n",
    "# # Delete the container image from Artifact Registry\n",
    "# !gcloud artifacts docker images delete \\\n",
    "#     --quiet \\\n",
    "#     --delete-tags \\\n",
    "#     {OUTPUT_IMAGE_URI}\n",
    "# delete_bucket = False\n",
    "\n",
    "# if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "#     ! gsutil rm -r $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb8e34-ef37-4c77-886e-7bd2175f4f7d",
   "metadata": {},
   "source": [
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/prediction/custom_prediction_routines/SDK_Pytorch_Custom_Predict.ipynb"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
